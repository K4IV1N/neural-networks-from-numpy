{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbb85043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60063ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(loader_fn, train_num, test_num):\n",
    "    data_x, data_y = loader_fn\n",
    "    \n",
    "    classes = xp.unique(data_y)\n",
    "    \n",
    "    train_x_list = []\n",
    "    train_y_list = []\n",
    "    test_x_list = []\n",
    "    test_y_list = []\n",
    "    \n",
    "    for cls in classes:\n",
    "        cls_indices = xp.where(data_y == cls)[0]\n",
    "        cls_indices = xp.random.permutation(cls_indices)\n",
    "        \n",
    "        X_cls = data_x[cls_indices]\n",
    "        Y_cls = data_y[cls_indices]\n",
    "        \n",
    "        train_x_list.append(X_cls[:train_num])\n",
    "        train_y_list.append(Y_cls[:train_num])\n",
    "        \n",
    "        test_x_list.append(X_cls[train_num:train_num + test_num])\n",
    "        test_y_list.append(Y_cls[train_num:train_num + test_num])\n",
    "        \n",
    "    X_train = xp.concatenate(train_x_list)\n",
    "    y_train = xp.concatenate(train_y_list)\n",
    "    X_test = xp.concatenate(test_x_list)\n",
    "    y_test = xp.concatenate(test_y_list)\n",
    "    \n",
    "    train_perm = xp.random.permutation(len(X_train))\n",
    "    X_train = X_train[train_perm]\n",
    "    y_train = y_train[train_perm]\n",
    "    \n",
    "    test_perm = xp.random.permutation(len(X_test))\n",
    "    X_test = X_test[test_perm]\n",
    "    y_test = y_test[test_perm]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29a1ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml  \n",
    "\n",
    "data = fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20ec3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = dataset((xp.asarray(data[\"data\"].values) / 255.0, xp.asarray(data[\"target\"].values.astype('int16'))), 3000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "310e5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.grad = xp.zeros_like(data)\n",
    "        \n",
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.params = {}\n",
    "        \n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, Parameter):\n",
    "            self.params[name] = value\n",
    "        super().__setattr__(name, value)\n",
    "        \n",
    "    def parameters(self):\n",
    "        params = list(self.params.values())\n",
    "        # print('params', params)\n",
    "        # print('dict', self.__dict__.values())\n",
    "        for attr in self.__dict__.values():\n",
    "            if isinstance(attr, Module):\n",
    "                params.extend(attr.parameters())\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "964f6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.W = Parameter(xp.random.randn(in_features, out_features) * 0.01)\n",
    "        self.b = Parameter(xp.zeros(out_features))\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x @ self.W.data + self.b.data\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.W.grad += self.x.T @ grad_output\n",
    "        self.b.grad += grad_output.sum(axis=0)\n",
    "        return grad_output @ self.W.data.T\n",
    "\n",
    "class ReLU(Module):\n",
    "    def forward(self, x):\n",
    "        self.mask = x > 0\n",
    "        return x * self.mask\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.mask\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, parameters, lr=0.01):\n",
    "        self.parameters = list(parameters)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.parameters:\n",
    "            param.data -= self.lr * param.grad\n",
    "            \n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.parameters:\n",
    "            param.grad.fill(0)\n",
    "\n",
    "\n",
    "def accuracy(logits, targets):\n",
    "    preds = xp.argmax(logits, axis=1)\n",
    "    return xp.mean(preds == targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b8a9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "\n",
    "        if y_true.ndim == 1:\n",
    "            # Convert 1D class indices to one-hot vectors\n",
    "            num_classes = y_pred.shape[1]\n",
    "            self.y_true = xp.eye(num_classes)[y_true]\n",
    "        else:\n",
    "            self.y_true = y_true\n",
    "\n",
    "        self.y_true = self.y_true.astype(y_pred.dtype)\n",
    "        loss = xp.mean((y_pred - self.y_true) ** 2)\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        return 2 * (self.y_pred - self.y_true) / self.y_true.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e519dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(784, 128)\n",
    "        self.relu1 = ReLU()\n",
    "        self.fc2 = Linear(128, 32)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc3 = Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_output = self.fc3.backward(grad_output)\n",
    "        grad_output = self.relu2.backward(grad_output)\n",
    "        grad_output = self.fc2.backward(grad_output)\n",
    "        grad_output = self.relu1.backward(grad_output)\n",
    "        grad_output = self.fc1.backward(grad_output)\n",
    "        return grad_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a0b110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary: Train Acc=0.1000, Train Loss=0.0899, Test Acc=0.1000, Test Loss=0.0899\n",
      "Epoch 2 Summary: Train Acc=0.1068, Train Loss=0.0896, Test Acc=0.1100, Test Loss=0.0897\n",
      "Epoch 3 Summary: Train Acc=0.2831, Train Loss=0.0873, Test Acc=0.2800, Test Loss=0.0876\n",
      "Epoch 4 Summary: Train Acc=0.3596, Train Loss=0.0771, Test Acc=0.3300, Test Loss=0.0775\n",
      "Epoch 5 Summary: Train Acc=0.5823, Train Loss=0.0665, Test Acc=0.5000, Test Loss=0.0664\n"
     ]
    }
   ],
   "source": [
    "loss_fn = MSE()\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "initial_lr = 0.01\n",
    "\n",
    "model = MyModel()\n",
    "optimizer = SGD(model.parameters(), lr=initial_lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        x_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        logits = model.forward(x_batch)\n",
    "        loss = loss_fn.forward(logits, y_batch)\n",
    "        grad_output = loss_fn.backward()\n",
    "        model.backward(grad_output)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    logits_train = model.forward(X_train)\n",
    "    train_loss = loss_fn.forward(logits_train, y_train)\n",
    "    train_acc = accuracy(logits_train, y_train)\n",
    "\n",
    "    logits_test = model.forward(X_test)\n",
    "    test_loss = loss_fn.forward(logits_test, y_test)\n",
    "    test_acc = accuracy(logits_test, y_test)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Summary: \"\n",
    "          f\"Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, \"\n",
    "          f\"Test Acc={test_acc:.4f}, Test Loss={test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "967c9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    state = {}\n",
    "    for name, module in model.__dict__.items():\n",
    "        if isinstance(module, Module):\n",
    "            for pname, p in module.params.items():\n",
    "                state[f\"{name}.{pname}\"] = p.data\n",
    "    xp.save(path, state)\n",
    "\n",
    "def load_model(model, path):\n",
    "    state = xp.load(path, allow_pickle=True).item()\n",
    "\n",
    "    for name, module in model.__dict__.items():\n",
    "        if isinstance(module, Module):\n",
    "            for pname, p in module.params.items():\n",
    "                key = f\"{name}.{pname}\"\n",
    "                if key in state:\n",
    "                    p.data = state[key]\n",
    "                else:\n",
    "                    print(\"Missing:\", key)\n",
    "\n",
    "    return model\n",
    "\n",
    "save_path = 'saved_1.npy'\n",
    "save_model(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a142ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = Linear(784, 128)\n",
    "        self.relu1 = ReLU()\n",
    "        self.fc2 = Linear(128, 32)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc3 = Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        grad_output = self.fc3.backward(grad_output)\n",
    "        grad_output = self.relu2.backward(grad_output)\n",
    "        grad_output = self.fc2.backward(grad_output)\n",
    "        grad_output = self.relu1.backward(grad_output)\n",
    "        grad_output = self.fc1.backward(grad_output)\n",
    "        return grad_output\n",
    "\n",
    "model_ = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b38f8998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {},\n",
       " 'fc1': <__main__.Linear at 0x1a6c5993580>,\n",
       " 'relu1': <__main__.ReLU at 0x1a6c5992590>,\n",
       " 'fc2': <__main__.Linear at 0x1a6c59922c0>,\n",
       " 'relu2': <__main__.ReLU at 0x1a6c59920e0>,\n",
       " 'fc3': <__main__.Linear at 0x1a6c5991f60>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3a2963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Parameter at 0x1a6c5990af0>,\n",
       " <__main__.Parameter at 0x1a6c5992980>,\n",
       " <__main__.Parameter at 0x1a6c5991a50>,\n",
       " <__main__.Parameter at 0x1a6c59924a0>,\n",
       " <__main__.Parameter at 0x1a6c5991c60>,\n",
       " <__main__.Parameter at 0x1a6c5991180>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "708c675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary: Train Acc=0.6683, Train Loss=0.0591, Test Acc=0.6400, Test Loss=0.0587\n",
      "Epoch 2 Summary: Train Acc=0.7657, Train Loss=0.0519, Test Acc=0.7500, Test Loss=0.0512\n",
      "Epoch 3 Summary: Train Acc=0.7998, Train Loss=0.0449, Test Acc=0.7800, Test Loss=0.0438\n",
      "Epoch 4 Summary: Train Acc=0.8164, Train Loss=0.0384, Test Acc=0.8000, Test Loss=0.0374\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = load_model(model_, save_path)\n",
    "\n",
    "# Reinitialize optimizer after loading the model\n",
    "optimizer = SGD(model1.parameters(), lr=initial_lr)\n",
    "\n",
    "# Continue with the training loop\n",
    "for epoch in range(4):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        x_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        logits = model1.forward(x_batch)\n",
    "        loss = loss_fn.forward(logits, y_batch)\n",
    "        grad_output = loss_fn.backward()\n",
    "        model1.backward(grad_output)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    logits_train = model1.forward(X_train)\n",
    "    train_loss = loss_fn.forward(logits_train, y_train)\n",
    "    train_acc = accuracy(logits_train, y_train)\n",
    "\n",
    "    logits_test = model1.forward(X_test)\n",
    "    test_loss = loss_fn.forward(logits_test, y_test)\n",
    "    test_acc = accuracy(logits_test, y_test)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Summary: \"\n",
    "          f\"Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, \"\n",
    "          f\"Test Acc={test_acc:.4f}, Test Loss={test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
