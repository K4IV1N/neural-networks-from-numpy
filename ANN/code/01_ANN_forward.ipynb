{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb489d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c79b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.grad = np.zeros_like(data)\n",
    "        \n",
    "class Module:\n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113f29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        # Normal mode: user specifies input and output size\n",
    "        if len(args) == 2:  # example: Linear(128, 32)\n",
    "            in_features, out_features = args\n",
    "            self.deferred_init = False\n",
    "            self.initialize_params(in_features, out_features)\n",
    "\n",
    "        # Deferred initialization: Linear(32)\n",
    "        elif len(args) == 1:\n",
    "            (out_features,) = args\n",
    "            self.deferred_init = True\n",
    "            self.out_features = out_features\n",
    "            self.W = None\n",
    "            self.b = None\n",
    "        else:\n",
    "            raise ValueError(\"Linear expects 1 or 2 arguments\")\n",
    "\n",
    "\n",
    "    def initialize_params(self, in_features, out_features):\n",
    "        # simple \n",
    "        # self.W = Parameter(np.random.randn(in_features, out_features) * 0.01)   # (in_features, out_features, )\n",
    "\n",
    "        # Kaiming He normal initialization (best for ReLU networks)\n",
    "        std = np.sqrt(2.0 / in_features)                    \n",
    "        self.W = Parameter(np.random.randn(in_features, out_features) * std)  # (in_features, out_features, )\n",
    "        \n",
    "        self.b = Parameter(np.zeros(out_features)) # (output_features,)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Deferred initialization\n",
    "        if self.deferred_init and self.W is None:\n",
    "            in_features = x.shape[-1]\n",
    "            self.initialize_params(in_features, self.out_features)\n",
    "            self.deferred_init = False\n",
    "\n",
    "        self.x = x\n",
    "        # x: (batch, in_features) \n",
    "        return x @ self.W.data + self.b.data    # (batch, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8dd1837",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def forward(self, x):\n",
    "        # Mask for positive elements (positive -> keep, else -> 0)\n",
    "        self.mask = x > 0\n",
    "        return x * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c4f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred  # Store predictions for backward pass\n",
    "\n",
    "        # If labels are 1D (class indices), convert them to one-hot encoding\n",
    "        if y_true.ndim == 1:\n",
    "            num_classes = y_pred.shape[1]   # Number of output classes\n",
    "            self.y_true = np.eye(num_classes)[y_true]   # One-hot encode\n",
    "        else:\n",
    "            self.y_true = y_true  # Already in proper shape\n",
    "\n",
    "        # Match dtype with predictions\n",
    "        self.y_true = self.y_true.astype(y_pred.dtype)\n",
    "\n",
    "        # Average of squared differences\n",
    "        loss = np.mean((y_pred - self.y_true) ** 2)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bcc3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred # Store predictions for backward pass\n",
    "\n",
    "        # If labels are 1D (class indices), convert them to one-hot encoding\n",
    "        if y_true.ndim == 1:\n",
    "            num_classes = y_pred.shape[1]  # Number of output classes\n",
    "            self.y_true = np.eye(num_classes)[y_true]  # One-hot encode\n",
    "        else:\n",
    "            self.y_true = y_true  # Already one-hot encoded\n",
    "\n",
    "        # Match dtype with predictions\n",
    "        self.y_true = self.y_true.astype(y_pred.dtype)\n",
    "\n",
    "        # Clip predictions to avoid log(0) which can cause numerical issues\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-12, 1.0)\n",
    "\n",
    "        # Compute cross-entropy loss:\n",
    "        #   - sum over classes for each sample\n",
    "        #   - then average over all samples\n",
    "        loss = -np.mean(np.sum(self.y_true * np.log(y_pred_clipped), axis=1))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92c99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (10, 10)\n",
      "Random labels: [4 4 7 8 8 2 1 3 8 1]\n",
      "logits: [-0.8690983   0.62165563 -0.07143504 -0.60895046 -0.24058133  0.60720407\n",
      " -0.1415443   0.67932762  0.57505472 -0.21747152]\n",
      "Predicted labels: [7 1 7 7 7 7 1 7 1 1]\n",
      "Loss: 0.5348666917144509\n"
     ]
    }
   ],
   "source": [
    "class MyModel:\n",
    "    def __init__(self):\n",
    "        self.fc1 = Linear(784, 128)\n",
    "        self.relu1 = ReLU()\n",
    "        self.fc2 = Linear(128, 32)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc3 = Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "batch_size = 10     # Number of samples\n",
    "num_classes = 10    # Number of class\n",
    "\n",
    "loss_fn = MSE()\n",
    "# loss_fn = CrossEntropy()\n",
    "\n",
    "# input (random images)\n",
    "X_random = np.random.rand(batch_size, 784)   # shape: (10,784)\n",
    "\n",
    "# labels (random class indices 0â€“9)\n",
    "y_indices = np.random.randint(0, num_classes, size=batch_size)\n",
    "\n",
    "# y_batch = np.eye(num_classes)[y_indices]\n",
    "# Not needed because we defined the loss to handle both label encoding and one-hot encoding.\n",
    "\n",
    "model = MyModel()   # Instantiate the model\n",
    "\n",
    "# Run forward pass\n",
    "logits = model.forward(X_random)\n",
    "loss = loss_fn.forward(logits, y_indices)\n",
    "\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(\"Random labels:\", y_indices)\n",
    "print(\"logits:\", logits[0])\n",
    "print(\"Predicted labels:\", np.argmax(logits, axis=1)) # Logits give class scores -> use np.argmax to convert to labels\n",
    "print(\"Loss:\", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
